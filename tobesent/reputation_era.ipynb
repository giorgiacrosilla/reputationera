{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reputation Era\n",
    "### How does the reputation of artists changes in time?\n",
    "\n",
    "This notebook contains the data mining and data analysis of the project Reoutation Era, developed by Erica Andreose, Giorgia Crosilla and Daniele Spedicati in the context of the exam of Information Visualization. \n",
    "\n",
    "The project aims to explore the oscillations in reputation that different artists face during time through data. \n",
    "\n",
    "The concept of reputation is difficult to define and many definition could be given [inserire qualche riferimento agli articoli.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Datasets\n",
    "In this project, we focused on three main variables to define the reputation of an artist:\n",
    "* Auctions [dire sorgente dati]\n",
    "* Pubblications about the artist [ dire sorgente dati]\n",
    "* One-Man Exhibition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Case studies - De Kooning and Klimt\n",
    "As an exaple for our study we took two well-known artist, De Kooning and Klimt. \n",
    "### De cooning - a \"ground trouth\" case. \n",
    "### Klimt - a research case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all useful libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Auctions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the auctions dataset as a Pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "auctions = pd.read_csv(\"auctions.csv\", sep=\";\", encoding=\"iso-8859-1\")\n",
    "auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(auctions['artist']):\n",
    "    if isinstance(item, str) and 'After  ' in item:\n",
    "        auctions.at[i, 'artist'] = item.replace('After  ', '')\n",
    "auctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Brief overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with the frequency of each artist\n",
    "\n",
    "from collections import Counter\n",
    "liss = {}\n",
    "for column_name in auctions.columns:\n",
    "    if column_name == \"artist\":\n",
    "        for value in auctions[column_name]:\n",
    "            if value not in liss:\n",
    "                liss[value] = 1\n",
    "            else:\n",
    "                liss[value] += 1\n",
    "k = Counter(liss)\n",
    " \n",
    "# Finding 20 highest values\n",
    "high = k.most_common(20) \n",
    " \n",
    "print(\"Initial Dictionary:\")\n",
    "print(liss, \"\\n\")\n",
    "print ('Total artist', len(liss))\n",
    " \n",
    " \n",
    "print(\"Dictionary with 3 highest values:\")\n",
    "print(\"Keys: Values\")\n",
    " \n",
    "for i in high:\n",
    "    print(i[0],\" :\",i[1],\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the distribution of data in our\n",
    "\n",
    "# Extract keys with value 1\n",
    "keys_with_value_1 = [key for key, value in k.items() if value == 1]\n",
    "\n",
    "# Count of keys with value 1\n",
    "count_keys_with_value_1 = len(keys_with_value_1)\n",
    "\n",
    "\n",
    "# Extract keys with value between 1 and 5\n",
    "keys_with_value_minor_5 = [key for key, value in k.items() if 1 < value <= 5]\n",
    "\n",
    "# Count of keys with value 5\n",
    "count_keys_with_value_minor_5 = len(keys_with_value_minor_5)\n",
    "\n",
    "\n",
    "# extract keys with value between 5 and 10\n",
    "keys_with_value_minor_10= [key for key, value in k.items() if 5 < value <= 10]\n",
    "\n",
    "# Count of keys with value between 5 and 10\n",
    "count_keys_with_value_minor_10 = len(keys_with_value_minor_10)\n",
    "\n",
    "\n",
    "# extract keys with value greater than 10\n",
    "keys_with_value_greater_10= [key for key, value in k.items() if value > 10]\n",
    "\n",
    "# Count of keys with value greater than 10\n",
    "count_keys_with_value_greater_10 = len(keys_with_value_greater_10)\n",
    "    \n",
    "\n",
    "# Organise data in a df\n",
    "\n",
    "data = {'labels':['Artist with one auction', 'Artists with maximum 5 auctions', 'Artist with maximum 10 auctions', 'Artists with more than 10 auctions'],\n",
    "        'values' : [count_keys_with_value_1, count_keys_with_value_minor_5, count_keys_with_value_minor_10, count_keys_with_value_greater_10]\n",
    "}\n",
    "\n",
    "auctions_count = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the sum of 'values' column\n",
    "total_value = auctions_count['values'].sum()\n",
    "\n",
    "# Add a new row with the label \"Artists in the dataset\" and the sum of all values\n",
    "new_row = {'labels': ['Artists in the dataset'], 'values': [total_value]}\n",
    "total_df = pd.DataFrame(new_row)\n",
    "# Concatenate the original DataFrame with the new total row DataFrame\n",
    "auctions_count = pd.concat([auctions_count, total_df], ignore_index=True)\n",
    "# Calculate percentages\n",
    "auctions_count['percentage'] = (auctions_count['values'] / total_value) * 100\n",
    "\n",
    "\n",
    "auctions_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create donut chart from data above\n",
    "\n",
    "# settings\n",
    "sizes = [count_keys_with_value_1, count_keys_with_value_minor_5, count_keys_with_value_minor_10, count_keys_with_value_greater_10]\n",
    "labels = ['Artist with one auction', 'Artists with maximum 5 auctions', 'Artist with maximum 10 auctions', 'Artists with more than 10 auctions']\n",
    "colors = ['#FFC3FF','#E9A2FF','#A664BC','#86469C']\n",
    "explode = [0, 0, 0, 0.1]\n",
    "# Create a pieplot\n",
    "plt.pie(sizes, labels=labels, colors=colors, explode=explode, autopct='%1.1f%%', startangle=0, pctdistance=0.5)\n",
    "\n",
    "# add a circle at the center to transform it in a donut chart\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.title('Distribution of Artists by Number of Auctions performed on their works of art', color = '#352f36')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bar chart of frequency of auctions for artists with more than 10 auctions performed on their works.\n",
    "\n",
    "#create dictionary with only above 10\n",
    "greater_10_dict = {}\n",
    "for key, value in high:\n",
    "    if value > 10 :\n",
    "        greater_10_dict[key] = value\n",
    "\n",
    "data = {'artist': greater_10_dict.keys(), 'number of auctions': greater_10_dict.values()}\n",
    "\n",
    "\n",
    "greater_10_df = pd.DataFrame(data)\n",
    "\n",
    "greater_10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a barplot of the artist with more than 10 aucitons performed on their works\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the style and color of the axes\n",
    "sns.set_style({'axes.edgecolor': 'gray'})\n",
    "\n",
    "sns.barplot(x='artist', y='number of auctions', data=greater_10_df, color='#86469C')\n",
    "plt.xticks(rotation=45, ha='right', color = '#352f36') \n",
    "plt.yticks(color = '#352f36')\n",
    "plt.title('Auctions perforemed on artist', color = '#352f36')\n",
    "plt.xlabel('Artist', color = '#352f36')\n",
    "plt.ylabel('Number of Auctions', color = '#352f36')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot without the top two\n",
    "greater_10_df_filtered = greater_10_df.iloc[2:]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the style and color of the axes\n",
    "sns.set_style({'axes.edgecolor': 'gray'})\n",
    "\n",
    "sns.barplot(x='artist', y='number of auctions', data=greater_10_df_filtered, color='#86469C')\n",
    "plt.xticks(rotation=45, ha='right', color = '#352f36') \n",
    "plt.yticks(color = '#352f36')\n",
    "plt.title('Auctions perforemed on artist', color = '#352f36')\n",
    "plt.xlabel('Artist', color = '#352f36')\n",
    "plt.ylabel('Number of Auctions', color = '#352f36')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "greater_10_df_filtered = greater_10_df.iloc[3:]\n",
    "\n",
    "greater_10_df_filtered.to_csv('../docs//data/greater_10_filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preliminary research shows us that the data in our dataset are not omogeneus. Although, we have a small group of istances that present an adequate number of data. The two artist that we are focusing on in this study (De Kooning and Klimt) are both in this subset. This encourage us to continue in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying two artists: De Kooning and Klimt\n",
    "## 1. Times a work has been sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count De Kooning frequency\n",
    "\n",
    "liss_dk = []\n",
    "for column_name in auctions.columns:\n",
    "    if column_name == \"artist\":\n",
    "        for value in auctions[column_name]:\n",
    "            if value == \"Willem de Kooning\":\n",
    "                liss_dk.append(value)\n",
    "print(len(liss_dk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only results related to sales on De Kooning works. Artworks that do not possess data about price or soldtime have been deleted from the dataset.\n",
    "The dataset does not possess any data related to sellers and buyers. \n",
    "In this example we notice that 307 works over a total of 381 possess data about price and time of the transaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_auctions_dk = auctions.loc[auctions[\"artist\"] == \"Willem de Kooning\", [\"artist\", \"name\", \"price\", \"soldtime\"]].copy()\n",
    "\n",
    "final_auctions_dk.dropna(subset=[\"price\", \"soldtime\"], inplace=True)\n",
    "\n",
    "\n",
    "# Extract the day from the \"soldtime\" column\n",
    "final_auctions_dk[\"soldtime\"] = final_auctions_dk[\"soldtime\"].str.split(\"-\").str[0]\n",
    "\n",
    "final_auctions_dk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "final_auctions_dk.to_csv('auctions_data_DK.csv', index=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "final_auctions_dk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are works that have been sold more than once\n",
    "\n",
    "name_counts = final_auctions_dk.groupby(['artist', 'name']).size().reset_index(name='count')\n",
    "\n",
    "name_counts_sorted_dk = name_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "name_counts_sorted_dk.reset_index(drop=True)\n",
    "\n",
    "name_counts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this initial overview we can notice that probably there are more than one \"Untitled\" work (the chances that one work was sold 90 times in eight years are very low). Our dataset did not provide a unique identifier for each work, which makes impossible to disambiguate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of works sold how many times\n",
    "\n",
    "# Count the occurrences of each count value\n",
    "count_freq = name_counts_sorted_dk['count'].value_counts().sort_index()\n",
    "\n",
    "# Create a DataFrame to store the count frequency data\n",
    "count_data_dk = pd.DataFrame({'times_sold':count_freq.index , 'count': count_freq.values})\n",
    "\n",
    "count_data_dk = count_data_dk.sort_values(by='times_sold', ascending=True)\n",
    "\n",
    "# Modify the 'times_sold' column to become a string\n",
    "count_data_dk['times_sold'] = 'sold ' + count_data_dk['times_sold'].astype(str) + ' times'\n",
    "\n",
    "count_data_dk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot\n",
    "\n",
    "# Set the style and color of the axes\n",
    "sns.set_style({'axes.edgecolor': 'gray'})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='times_sold', y='count', data=count_data_dk, color='#E97D01')\n",
    "plt.title('Frequency of Count Values', color = '#352f36')\n",
    "plt.xlabel('Times Sold', color = '#352f36')\n",
    "plt.ylabel('Count', color = '#352f36')\n",
    "plt.xticks(rotation=45, color = '#352f36')\n",
    "plt.yticks(color = '#352f36')\n",
    "\n",
    "# Add exact value on top of each bar\n",
    "for index, value in enumerate(count_data_dk['count']):\n",
    "    plt.text(index, value + 0.5, str(value), ha='center', va='bottom', color = '#352f36')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Klimt frequency\n",
    "\n",
    "liss_k = []\n",
    "for column_name in auctions.columns:\n",
    "    if column_name == \"artist\":\n",
    "        for value in auctions[column_name]:\n",
    "            if value == \"Gustav Klimt\":\n",
    "                liss_k.append(value)\n",
    "print(len(liss_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klimt data\n",
    "\n",
    "final_auctions_k = auctions[[\"artist\", \"name\", \"price\", \"soldtime\"]].copy()\n",
    "final_auctions_k= final_auctions_k[final_auctions_k[\"artist\"] == \"Gustav Klimt\"].copy()\n",
    "\n",
    "final_auctions_k.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for idx, row in final_auctions_k.iterrows():\n",
    "    if pd.isna(row[\"price\"]) and pd.isna(row[\"soldtime\"]):\n",
    "        final_auctions_k.drop(idx, inplace=True)\n",
    "        \n",
    "dayy = []\n",
    "for i in final_auctions_k['soldtime']:\n",
    "    string_representation = str(i)\n",
    "    split_parts = string_representation.split('-')\n",
    "    day = split_parts[0]\n",
    "    dayy.append(day)\n",
    "final_auctions_k['soldtime'] = dayy\n",
    "        \n",
    "\n",
    "final_auctions_k.reset_index(drop=True, inplace=True)\n",
    "final_auctions_k.to_csv('auctions_data_k.csv', index=False)\n",
    "final_auctions_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are works that have been sold more than once\n",
    "\n",
    "name_counts = final_auctions_k.groupby(['artist', 'name']).size().reset_index(name='count')\n",
    "\n",
    "name_counts_sorted_k = name_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "name_counts_sorted_k.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of works sold how many times\n",
    "\n",
    "# Count the occurrences of each count value\n",
    "count_freq = name_counts_sorted_k['count'].value_counts().sort_index()\n",
    "\n",
    "# Create a DataFrame to store the count frequency data\n",
    "count_data_k = pd.DataFrame({'times_sold':count_freq.index , 'count': count_freq.values})\n",
    "\n",
    "count_data_k = count_data_k.sort_values(by='times_sold', ascending=True)\n",
    "\n",
    "# Modify the 'times_sold' column to become a string\n",
    "count_data_k['times_sold'] = 'sold ' + count_data_k['times_sold'].astype(str) + ' times'\n",
    "\n",
    "count_data_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='times_sold', y='count', data=count_data_k, color='#26408B')\n",
    "plt.title('Frequency of Count Values')\n",
    "plt.xlabel('Times Sold')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add exact value on top of each bar\n",
    "for index, value in enumerate(count_data_k['count']):\n",
    "    plt.text(index, value + 0.5, str(value), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine data\n",
    "\n",
    "# Left merge df_dk and df_k on 'times_sold' column\n",
    "soldtime_merge_df = pd.merge(count_data_dk, count_data_k, on='times_sold', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "soldtime_merge_df = soldtime_merge_df.fillna(0)\n",
    "\n",
    "# Rename the 'count' columns\n",
    "soldtime_merge_df = soldtime_merge_df.rename(columns={'count_x': 'de_kooning_count', 'count_y': 'klimt_count'})\n",
    "\n",
    "# Convert count columns to integer data type\n",
    "soldtime_merge_df['de_kooning_count'] = soldtime_merge_df['de_kooning_count'].astype(int)\n",
    "soldtime_merge_df['klimt_count'] = soldtime_merge_df['klimt_count'].astype(int)\n",
    "\n",
    "soldtime_merge_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bars\n",
    "barWidth = 0.3\n",
    " \n",
    "# set heights of bars\n",
    "bars1 = soldtime_merge_df['de_kooning_count']\n",
    "bars2 = soldtime_merge_df['klimt_count']\n",
    "\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Make the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(r1, bars1, color='#E97D01', width=barWidth, edgecolor='white', label='De Kooning')\n",
    "plt.bar(r2, bars2, color='#26408B', width=barWidth, edgecolor='white', label='Klimt')\n",
    "\n",
    "for i, (dk_count, kl_count) in enumerate(zip(soldtime_merge_df['de_kooning_count'], soldtime_merge_df['klimt_count'])):\n",
    "    if dk_count > 0:\n",
    "        plt.text(i, dk_count + 0.5, str(dk_count), ha='center', va='bottom')\n",
    "    if kl_count > 0:\n",
    "        plt.text(i + barWidth, kl_count + 0.5, str(kl_count), ha='center', va='bottom')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.title('Frequency of Count Values')\n",
    "plt.xlabel('group', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], soldtime_merge_df['times_sold'], rotation=45)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "soldtime_merge_df.to_csv('../docs/data/soldtime_merge_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first analys shows the dinamicity of the two artist: while more works by Klimt were sold, De Kooning's ones seem to be more mobile, capturing more the interst of the market???."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sellings per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Count the values in the 'soldtime' column\n",
    "soldtime_counts_dk = final_auctions_dk['soldtime'].value_counts()\n",
    "\n",
    "# Convert the Series to a DataFrame if needed\n",
    "soldtime_counts_df = soldtime_counts_dk.reset_index()\n",
    "soldtime_counts_df.columns = ['soldtime', 'count']\n",
    "\n",
    "# Sort the DataFrame by the 'soldtime' column\n",
    "soldtime_counts_df_sorted_dk = soldtime_counts_df.sort_values(by='soldtime')\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "soldtime_counts_df_sorted_dk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot timeline\n",
    "\n",
    "sns.lineplot(x = \"soldtime\", y = \"count\", data = soldtime_counts_df_sorted_dk, color='#E97D01') \n",
    "  \n",
    "plt.xticks(rotation = 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming new_dataframe_dk is your DataFrame\n",
    "# Assuming the column name is 'soldtime'\n",
    "\n",
    "# Count the values in the 'soldtime' column\n",
    "soldtime_counts_k = final_auctions_k['soldtime'].value_counts()\n",
    "\n",
    "# Convert the Series to a DataFrame if needed\n",
    "soldtime_counts_df = soldtime_counts_k.reset_index()\n",
    "soldtime_counts_df.columns = ['soldtime', 'count']\n",
    "\n",
    "# Sort the DataFrame by the 'soldtime' column\n",
    "soldtime_counts_df_sorted_k = soldtime_counts_df.sort_values(by='soldtime')\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "soldtime_counts_df_sorted_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot timeline\n",
    "\n",
    "sns.lineplot(x = \"soldtime\", y = \"count\", data = soldtime_counts_df_sorted_k, color='#26408B') \n",
    "  \n",
    "plt.xticks(rotation = 25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert 'soldtime' columns to int64 if they are not already\n",
    "soldtime_counts_df_sorted_dk['soldtime'] = soldtime_counts_df_sorted_dk['soldtime'].astype('int64')\n",
    "soldtime_counts_df_sorted_k['soldtime'] = soldtime_counts_df_sorted_k['soldtime'].astype('int64')\n",
    "\n",
    "# Right merge the DataFrames on the 'soldtime' column\n",
    "selling_per_year = pd.merge(soldtime_counts_df_sorted_dk, soldtime_counts_df_sorted_k, on='soldtime', how='right')\n",
    "\n",
    "# Rename the count columns\n",
    "selling_per_year.rename(columns={'count_x': 'de kooning count', 'count_y': 'klimt count'}, inplace=True)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "selling_per_year.fillna(0, inplace=True)\n",
    "\n",
    "# Convert the count columns to int64\n",
    "selling_per_year['de kooning count'] = selling_per_year['de kooning count'].astype('int64')\n",
    "selling_per_year['klimt count'] = selling_per_year['klimt count'].astype('int64')\n",
    "\n",
    "# Sort by 'soldtime'\n",
    "selling_per_year.sort_values(by='soldtime', inplace=True)\n",
    "\n",
    "# Display the merged and sorted DataFrame\n",
    "selling_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a new figure and axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot \"de kooning count\"\n",
    "ax = sns.lineplot(x=\"soldtime\", y=\"de kooning count\", data=selling_per_year, color='#E97D01')\n",
    "\n",
    "# Plot \"klimt count\" on the same axes\n",
    "sns.lineplot(x=\"soldtime\", y=\"klimt count\", data=selling_per_year, color='#26408B', ax=ax)\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=25)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Sold Time')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selling_per_year.to_csv('../docs/data/selling_per_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. All sellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing sellings at time and price De Kooning\n",
    "\n",
    "# Convert 'soldtime' and 'price' columns to numeric data types if they are not already\n",
    "final_auctions_dk['soldtime'] = pd.to_numeric(final_auctions_dk['soldtime'], errors='coerce')\n",
    "final_auctions_dk['price'] = pd.to_numeric(final_auctions_dk['price'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values if any\n",
    "final_auctions_dk = final_auctions_dk.dropna(subset=['soldtime', 'price'])\n",
    "\n",
    "# Plot the scatter plot with regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='soldtime', y='price', data=final_auctions_dk, color='#E97D01')\n",
    "\n",
    "# Set the labels and title\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.xlabel('Sold Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Scatter Plot of Sold Time vs. Price with Regression Line')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown this way, it is difficult to understand the actual amount of values for each layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the 'price' values to the nearest million\n",
    "rounded_prices = (final_auctions_dk['price'] // 10000000) * 10000000\n",
    "\n",
    "# Create a new DataFrame with 'soldtime', 'rounded_prices', and 'count'\n",
    "count_df_dk = final_auctions_dk.groupby(['soldtime', rounded_prices]).size().reset_index(name='count')\n",
    "\n",
    "# Rename columns\n",
    "count_df_dk.rename(columns={rounded_prices.name: 'rounded_prices'}, inplace=True)\n",
    "\n",
    "# Sort the DataFrame by 'soldtime'\n",
    "count_df_dk.sort_values(by='soldtime', inplace=True)\n",
    "\n",
    "# Display the new DataFrame\n",
    "count_df_dk\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# # Define the two colors\n",
    "# color1 = '#FCAC23'  # Yellow\n",
    "# color2 = '#B53302'  # Red\n",
    "\n",
    "\n",
    "# # Create a custom colormap gradient\n",
    "# cmap = LinearSegmentedColormap.from_list('custom_gradient', [color1, color2])\n",
    "\n",
    "# # Assuming count_df is your DataFrame\n",
    "\n",
    "\n",
    "# # Create the bubble chart with color gradient based on 'count'\n",
    "# plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "# sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=count_df_dk, legend=True, palette=cmap, sizes=(50,200))\n",
    "\n",
    "# # Set the labels and title\n",
    "# plt.xlabel('Sold Time')\n",
    "# plt.ylabel('Rounded Price')\n",
    "# plt.title('Bubble Chart of Sold Time vs. Rounded Price')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing sellings at time and price Klimt\n",
    "\n",
    "# Convert 'soldtime' and 'price' columns to numeric data types if they are not already\n",
    "final_auctions_k['soldtime'] = pd.to_numeric(final_auctions_k['soldtime'], errors='coerce')\n",
    "final_auctions_k['price'] = pd.to_numeric(final_auctions_k['price'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values if any\n",
    "final_auctions_dk = final_auctions_dk.dropna(subset=['soldtime', 'price'])\n",
    "\n",
    "# Plot the scatter plot with regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='soldtime', y='price', data=final_auctions_k, color='#26408B')\n",
    "\n",
    "# Set the labels and title\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.xlabel('Sold Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Scatter Plot of Sold Time vs. Price with Regression Line')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as for de Kooning, we now show de distribution of values to make more explicit the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the 'price' values to the nearest million\n",
    "rounded_prices = (final_auctions_k['price'] // 10000000) * 10000000\n",
    "\n",
    "# Create a new DataFrame with 'soldtime', 'rounded_prices', and 'count'\n",
    "count_df_k = final_auctions_k.groupby(['soldtime', rounded_prices]).size().reset_index(name='count')\n",
    "\n",
    "# Rename columns\n",
    "count_df_k.rename(columns={rounded_prices.name: 'rounded_prices'}, inplace=True)\n",
    "\n",
    "# Sort the DataFrame by 'soldtime'\n",
    "count_df_k.sort_values(by='soldtime', inplace=True)\n",
    "\n",
    "# Display the new DataFrame\n",
    "count_df_k\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the two colors\n",
    "# color1 = '#81B1D5'  # Light blue\n",
    "# color2 = '#0F084B'  # Dark blue\n",
    "\n",
    "\n",
    "# # Create a custom colormap gradient\n",
    "# cmap = LinearSegmentedColormap.from_list('custom_gradient', [color1, color2])\n",
    "\n",
    "\n",
    "# # Create the bubble chart with color gradient based on 'count'\n",
    "# plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "# sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=count_df_k, legend=True, palette=cmap, sizes=(50,200))\n",
    "\n",
    "# # Set the labels and title\n",
    "# plt.xlabel('Sold Time')\n",
    "# plt.ylabel('Rounded Price')\n",
    "# plt.title('Bubble Chart of Sold Time vs. Rounded Price')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comparison scatterplot\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming new_dataframe_k and final_auctions_dk are your DataFrames containing \n",
    "# # Create a figure with two subplots\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True)\n",
    "\n",
    "# # Plot the first scatter plot with data from new_dataframe_k\n",
    "# sns.scatterplot(x='soldtime', y='price', data=new_dataframe_k, ax=axs[0])\n",
    "# axs[0].set_title('Scatter Plot of Sold Time vs. Price - K Data')\n",
    "# axs[0].set_ylabel('Price')\n",
    "\n",
    "# # Plot the second scatter plot with data from final_auctions_dk\n",
    "# sns.scatterplot(x='soldtime', y='price', data=final_auctions_dk, ax=axs[1])\n",
    "# axs[1].set_title('Scatter Plot of Sold Time vs. Price - DK Data')\n",
    "# axs[1].set_xlabel('Sold Time')\n",
    "# axs[1].set_ylabel('Price')\n",
    "\n",
    "# # Match x-axis limits of the second subplot to the first subplot\n",
    "# axs[1].set_xlim(axs[0].get_xlim())\n",
    "\n",
    "# # Match y-axis limits of the second subplot to the first subplot\n",
    "# axs[1].set_ylim(axs[0].get_ylim())\n",
    "\n",
    "# # Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define the two colors\n",
    "color1 = '#FCAC23'  # Yellow\n",
    "color2 = '#B53302'  # Red\n",
    "\n",
    "\n",
    "# Create a custom colormap gradient\n",
    "cmap_orange = LinearSegmentedColormap.from_list('custom_gradient', [color1, color2])\n",
    "\n",
    "# Define the two colors for the custom gradient\n",
    "color3 = '#81B1D5'  # Light blue\n",
    "color4 = '#0F084B'  # Dark blue\n",
    "\n",
    "# Create a custom colormap gradient\n",
    "cmap_blue = LinearSegmentedColormap.from_list('custom_gradient', [color3, color4])\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for count_df_dk\n",
    "sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=count_df_dk, ax=axs[0], legend=True, palette=cmap_orange, sizes=(50,200))\n",
    "axs[0].set_title('Count DataFrame DK')\n",
    "axs[0].set_xlabel('Sold Time')\n",
    "axs[0].set_ylabel('Rounded Price')\n",
    "\n",
    "# Plot for count_df_k\n",
    "sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=count_df_k, ax=axs[1], legend=True, palette=cmap_blue, sizes=(50,200))\n",
    "axs[1].set_title('Count DataFrame K')\n",
    "axs[1].set_xlabel('Sold Time')\n",
    "axs[1].set_ylabel('Rounded Price')\n",
    "\n",
    "# Match x-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_xlim(axs[1].get_xlim())\n",
    "\n",
    "# Match y-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_ylim(axs[1].get_ylim())\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis shows us that The the price for both Klimt and De Koning wors are pretty similar, and that interest in De Kooning is way higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying the median\n",
    "The graph above makes clear that the outliers are many, moslty for klimt. so better using the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median price per year de Kooning\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "mean_price = final_auctions_dk['price'].mean()\n",
    "\n",
    "print('overall median:', mean_price)\n",
    "\n",
    "\n",
    "# Calculate the mean price for each value of 'soldtime'\n",
    "mean_price_per_year_dk = final_auctions_dk.groupby('soldtime')['price'].mean()\n",
    "\n",
    "\n",
    "# Assuming 'mean_price_per_year_dk' is the Series containing mean price per year\n",
    "mean_price_per_year_dk_df = mean_price_per_year_dk.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "mean_price_per_year_dk_df.columns = ['soldtime', 'count']\n",
    "# Print the mean price for each year\n",
    "mean_price_per_year_dk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the variation of mean price per year\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# mean_price_per_year_dk.plot(kind='line', marker='o', color='#E97D01')\n",
    "# plt.title('Mean Price Variation per Year')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Mean Price')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median price per year Klimt\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "mean_price = final_auctions_k['price'].median()\n",
    "\n",
    "print('overall mean:', mean_price)\n",
    "\n",
    "\n",
    "# Calculate the mean price for each value of 'soldtime'\n",
    "mean_price_per_year_k = final_auctions_k.groupby('soldtime')['price'].median()\n",
    "\n",
    "\n",
    "# Print the mean price for each year\n",
    "mean_price_per_year_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the variation of mean price per year\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# mean_price_per_year_k.plot(kind='line', marker='o', color='#26408B')\n",
    "# plt.title('Mean Price Variation per Year')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Mean Price')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define the two colors for the custom gradient\n",
    "color1 = '#FCAC23'  # Yellow\n",
    "color2 = '#B53302'  # Red\n",
    "color3 = '#81B1D5'  # Light blue\n",
    "color4 = '#0F084B'  # Dark blue\n",
    "\n",
    "# Create custom colormaps\n",
    "cmap_orange = LinearSegmentedColormap.from_list('custom_gradient_orange', [color1, color2])\n",
    "cmap_blue = LinearSegmentedColormap.from_list('custom_gradient_blue', [color3, color4])\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for count_df_dk\n",
    "sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=count_df_dk, ax=axs[0], legend=True, palette=cmap_orange, sizes=(50,200), alpha=0.8)\n",
    "axs[0].set_title('Count DataFrame DK')\n",
    "axs[0].set_xlabel('Sold Time')\n",
    "axs[0].set_ylabel('Rounded Price')\n",
    "\n",
    "# Plot the line plot for mean price per year for final_auctions_dk\n",
    "mean_price_per_year_dk = final_auctions_dk.groupby('soldtime')['price'].mean()\n",
    "axs[0].plot(mean_price_per_year_dk.index, mean_price_per_year_dk.values, color='#E97D01', linestyle='-', linewidth=1)\n",
    "\n",
    "# Plot for count_df_k\n",
    "sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=count_df_k, ax=axs[1], legend=True, palette=cmap_blue, sizes=(50,200), alpha=0.8)\n",
    "axs[1].set_title('Count DataFrame K')\n",
    "axs[1].set_xlabel('Sold Time')\n",
    "axs[1].set_ylabel('Rounded Price')\n",
    "\n",
    "# Plot the line plot for mean price per year for new_dataframe_k\n",
    "mean_price_per_year_k = final_auctions_k.groupby('soldtime')['price'].mean()\n",
    "axs[1].plot(mean_price_per_year_k.index, mean_price_per_year_k.values, color='#26408B', linestyle='-', linewidth=1)\n",
    "\n",
    "# Match x-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_xlim(axs[1].get_xlim())\n",
    "\n",
    "# Match y-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_ylim(axs[1].get_ylim())\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df_dk.to_csv('../docs/data/rounded_count_dk.csv', index=False)\n",
    "mean_price_per_year_dk.to_csv('../docs/data/mean_price_per_year_dk.csv', index=False)\n",
    "count_df_k.to_csv('../docs/data/rounded_count_k.csv', index=False)\n",
    "mean_price_per_year_k.to_csv('../docs/data/mean_price_per_year_k.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of sellings per year\n",
    "\n",
    "qui mostro il numero di vendite per anno e la media di prezzo (la dimensione della palla). Dici che sarebbe meglio fare i guadagni totali?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "mean_price = final_auctions_dk['price'].mean()\n",
    "\n",
    "print('overall mean:', mean_price)\n",
    "\n",
    "\n",
    "# Calculate the mean price for each value of 'soldtime'\n",
    "mean_price_per_year_dk = final_auctions_dk.groupby('soldtime')['price'].median()\n",
    "\n",
    "\n",
    "# Print the mean price for each year\n",
    "mean_price_per_year_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming final_auctions_dk is your DataFrame with columns 'soldtime' and 'price'\n",
    "\n",
    "# Group by 'soldtime' and calculate count and mean\n",
    "grouped_data_dk = final_auctions_dk.groupby('soldtime')['price'].agg(['mean', 'count'])\n",
    "\n",
    "# Reset index to flatten the hierarchical index\n",
    "grouped_data_dk.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns as desired\n",
    "grouped_data_dk.columns = ['soldtime', 'mean', 'count']\n",
    "\n",
    "grouped_data_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the two colors\n",
    "# color1 = '#FCAC23'  # Yellow\n",
    "# color2 = '#B53302'  # Red\n",
    "\n",
    "# # Create a custom colormap gradient\n",
    "# cmap = LinearSegmentedColormap.from_list('custom_gradient', [color1, color2])\n",
    "\n",
    "\n",
    "# # Create the bubble chart with color gradient based on 'count'\n",
    "# plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# # use the scatterplot function to build the bubble map\n",
    "# sns.scatterplot(data=grouped_data_dk, x=\"soldtime\", y=\"count\", size=\"mean\", hue='mean', legend=True, sizes=(50, 200), palette=cmap)\n",
    "\n",
    "# # show the graph\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "mean_price = final_auctions_k['price'].mean()\n",
    "\n",
    "print('overall mean:', mean_price)\n",
    "\n",
    "\n",
    "# Calculate the mean price for each value of 'soldtime'\n",
    "mean_price_per_year_k = final_auctions_k.groupby('soldtime')['price'].mean()\n",
    "\n",
    "\n",
    "# Print the mean price for each year\n",
    "mean_price_per_year_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming new_dataframe_dk is your DataFrame with columns 'soldtime' and 'price'\n",
    "\n",
    "# Group by 'soldtime' and calculate count and mean\n",
    "grouped_data_k = final_auctions_k.groupby('soldtime')['price'].agg(['mean', 'count'])\n",
    "\n",
    "# Reset index to flatten the hierarchical index\n",
    "grouped_data_k.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns as desired\n",
    "grouped_data_k.columns = ['soldtime', 'mean', 'count']\n",
    "\n",
    "grouped_data_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color3 = '#81B1D5'  # Light blue\n",
    "# color4 = '#0F084B'  # Dark blue\n",
    "\n",
    "# cmap_blue = LinearSegmentedColormap.from_list('custom_gradient_blue', [color3, color4])\n",
    "\n",
    "\n",
    "\n",
    "# # Create the bubble chart with color gradient based on 'count'\n",
    "# plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# # use the scatterplot function to build the bubble map\n",
    "# sns.scatterplot(data=grouped_data_k, x=\"soldtime\", y=\"count\", size=\"mean\", hue='mean', legend=True, sizes=(50, 200), palette=cmap_blue)\n",
    "\n",
    "# # show the graph\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the two colors for the custom gradient\n",
    "color1 = '#FCAC23'  # Yellow\n",
    "color2 = '#B53302'  # Red\n",
    "color3 = '#81B1D5'  # Light blue\n",
    "color4 = '#0F084B'  # Dark blue\n",
    "\n",
    "\n",
    "cmap_orange = LinearSegmentedColormap.from_list('custom_gradient_blue', [color1, color2])\n",
    "\n",
    "\n",
    "cmap_blue = LinearSegmentedColormap.from_list('custom_gradient_blue', [color3, color4])\n",
    "\n",
    "# Determine the maximum size value from both DataFrames\n",
    "max_size = grouped_data_dk['mean'].max() * 200 / grouped_data_k['mean'].max()\n",
    "\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for grouped_data_dk\n",
    "sns.scatterplot(data=grouped_data_dk, x=\"soldtime\", y=\"count\", size=\"mean\", sizes=(50, max_size), hue='mean', ax=axs[0], legend='brief', palette=cmap_orange, alpha=0.8)\n",
    "axs[0].set_title('Count DataFrame DK')\n",
    "axs[0].set_xlabel('Price Mean')\n",
    "axs[0].set_ylabel('Rounded Price')\n",
    "\n",
    "# Plot for grouped_data_k\n",
    "sns.scatterplot(data=grouped_data_k, x=\"soldtime\", y=\"count\", size=\"mean\", sizes=(50, 200), hue='mean', ax=axs[1], legend='brief', palette=cmap_blue, alpha=0.8)\n",
    "axs[1].set_title('Count DataFrame K')\n",
    "axs[1].set_xlabel('Sold Time')\n",
    "axs[1].set_ylabel('Price Mean')\n",
    "\n",
    "# Match x-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_xlim(axs[1].get_xlim())\n",
    "\n",
    "# Match y-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_ylim(axs[1].get_ylim())\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webscraping collections data and general bibliography\n",
    "\n",
    "\n",
    "### query on data.bnf De Kooning\n",
    "\n",
    "it's not possible to do a query directly using python, so this query was performed here <a href=\"https://data.bnf.fr/sparql/\">data.bnf</a>:\n",
    "```\n",
    "PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX bnf-onto: <http://data.bnf.fr/ontology/bnf-onto/>\n",
    "SELECT * \n",
    "WHERE {\n",
    "  ?work dct:title ?title ;\n",
    "        dct:publisher ?publisher;\n",
    "        dct:date ?date;\n",
    "        rdfs:seeAlso ?uri ;\n",
    "        bnf-onto:isbn ?isbn;\n",
    "        \n",
    "  FILTER (bif:contains(?title, \"De_Kooning\"))}\n",
    "\n",
    "```\n",
    "\n",
    "has been done on the web endpoint and then the CSV was downloaded, this query searches data both in bnf catalogue and bnf.data.\n",
    "\n",
    "\n",
    "```\n",
    "PREFIX rdarelationships: <http://rdvocab.info/RDARelationshipsWEMI/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX bnf-onto: <http://data.bnf.fr/ontology/bnf-onto/>\n",
    "SELECT distinct ?work ?title ?creatorname ?date ?isbn\n",
    "WHERE {\n",
    "  ?work dct:title ?title;\n",
    "        dct:creator ?creator.\n",
    "\t\t?creator foaf:name ?creatorname.\n",
    "  ?work dct:date ?date.\n",
    "  ?work rdarelationships:expressionOfWork ?expression.\n",
    "?manifestation rdarelationships:expressionManifested ?expression.\n",
    "?manifestation bnf-onto:isbn ?isbn.  \n",
    "  FILTER (bif:contains(?title, \"De_Kooning\"))}\n",
    "```\n",
    "\n",
    "questa query ritorna anche l'autore, assieme ad ISBN, il problema  che i risultati tra la prima e la seconda query non corrispondono. Penso perch si lavora a livello di expression (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bnf_dk = pd.read_csv(\"databnf_DK.csv\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "bnf_dk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liss = []\n",
    "for column_name in bnf_dk.columns:\n",
    "    if column_name == \"title\":\n",
    "        for value in bnf_dk[column_name]:\n",
    "            if \"de Kooning\" in value or \"De Kooning\" in value:\n",
    "                liss.append(value)\n",
    "print(len(liss))\n",
    "\n",
    "row_count = bnf_dk.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in bnf_dk.columns:\n",
    "    if column_name == \"isbn\":\n",
    "        for i, value in enumerate(bnf_dk[column_name]):\n",
    "            if \"-\" in value:\n",
    "                # Replacing hyphens with empty string\n",
    "                bnf_dk.at[i, column_name] = value.replace(\"-\", \"\")\n",
    "bnf_dk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query on google books api - De Kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_books(query, max_results=40):\n",
    "    base_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "    start_index = 0\n",
    "    all_results = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"startIndex\": start_index,\n",
    "            \"maxResults\": max_results\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            items = data.get(\"items\", [])\n",
    "            if not items:\n",
    "                break\n",
    "            all_results.extend(items)\n",
    "            start_index += max_results\n",
    "        else:\n",
    "            print(\"Failed to retrieve data. Status code:\", response.status_code)\n",
    "            break\n",
    "\n",
    "    return all_results\n",
    "\n",
    "books_dk = fetch_books(\"De Kooning\")\n",
    "\n",
    "# Saving JSON data to a file\n",
    "with open(\"dkbooks.json\", \"w\") as json_file:\n",
    "    json.dump(books_dk, json_file, indent=4)\n",
    "\n",
    "print(\"JSON data saved to dkbooks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON data from file\n",
    "with open(\"dkbooks.json\", \"r\") as json_file:\n",
    "    books_data_dk = json.load(json_file)\n",
    "\n",
    "# Extract relevant fields from each book item\n",
    "books_list_dk = []\n",
    "for book in books_data_dk:\n",
    "    book_info = {\n",
    "        \"Title\": book[\"volumeInfo\"].get(\"title\", \"N/A\"),\n",
    "        \"Subtitle\": book[\"volumeInfo\"].get(\"subtitle\", \"N/A\"),\n",
    "        \"Authors\": \", \".join(book[\"volumeInfo\"].get(\"authors\", [\"N/A\"])),\n",
    "        \"Publisher\": book[\"volumeInfo\"].get(\"publisher\", \"N/A\"),\n",
    "        \"PublishedDate\": book[\"volumeInfo\"].get(\"publishedDate\", \"N/A\"),\n",
    "        \"isbn\": book[\"volumeInfo\"].get(\"industryIdentifiers\", [{}])[0].get(\"identifier\", \"N/A\"),  # Retrieving ISBN\n",
    "    }\n",
    "    books_list_dk.append(book_info)\n",
    "\n",
    "# Create DataFrame\n",
    "books_df_dk = pd.DataFrame(books_list_dk)\n",
    "books_df_dk.replace('N/A', np.nan, inplace= True)\n",
    "\n",
    "# Display DataFrame\n",
    "books_df_dk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liss = []\n",
    "for column_name in books_df_dk.columns:\n",
    "    if column_name == \"Title\":\n",
    "        for value in books_df_dk[column_name]:\n",
    "            if \"de Kooning\" in value or \"De Kooning\" in value:\n",
    "                liss.append(value)\n",
    "print(len(liss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming books_df is your DataFrame\n",
    "new_dataframe_dk = books_df_dk[books_df_dk[\"Title\"].str.contains(\"de Kooning\", case=False) & ~books_df_dk[\"Title\"].str.contains(\"Elaine de Kooning\", case=False)].copy()\n",
    "\n",
    "new_dataframe_dk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_dataframe_dk.head()\n",
    "# questo df ha  5 in meno del numero riportato sopra. perch sono stati eliminati i valori della moglie di de kooning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'ISBN' column\n",
    "df_combined_dk= pd.merge(bnf_dk, new_dataframe_dk, on='isbn', how='inner')\n",
    "\n",
    "# Display the new DataFrame with rows where ISBN is found in both DataFrames\n",
    "df_combined_dk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'Title' column in df2 to 'title'\n",
    "new_dataframe_dk.rename(columns={'Title': 'title'}, inplace=True)\n",
    "new_dataframe_dk.rename(columns={'PublishedDate': 'date'}, inplace=True)\n",
    "new_dataframe_dk.rename(columns={'Publisher': 'publisher'}, inplace=True)\n",
    "# Concatenate the DataFrames vertically\n",
    "combined_df = pd.concat([bnf_dk, new_dataframe_dk], ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on 'isbn' column\n",
    "new_df_dk = combined_df.drop_duplicates(subset='isbn')\n",
    "new_df_dk = combined_df.drop_duplicates(subset=['title', 'publisher', 'date'], keep='first')\n",
    "# Reset index of the new DataFrame\n",
    "new_df_dk.reset_index(drop=True, inplace=True)\n",
    "new_df_dk.drop(columns=['work', 'uri'], inplace=True)\n",
    "index_column = new_df_dk.columns.get_loc('Subtitle')\n",
    "\n",
    "# Move the column to position 2\n",
    "new_column_order = list(new_df_dk.columns)\n",
    "new_column_order.insert(1, new_column_order.pop(index_column))\n",
    "new_df_dk = new_df_dk[new_column_order]\n",
    "\n",
    "for i, date_value in enumerate(new_df_dk['date']):\n",
    "    # Convert integer to string before splitting\n",
    "    date_str = str(date_value)\n",
    "    # Split the date string by '-'\n",
    "    date_components = date_str.split('-')[0]\n",
    "    if '*' in date_components:\n",
    "        date_components = date_components.replace('*', '')  # Update here\n",
    "    # Update the 'date' column with the list of components\n",
    "    new_df_dk.at[i, 'date'] = date_components\n",
    "    \n",
    "for i in new_df_dk['Subtitle']:\n",
    "    if pd.isna(i):\n",
    "        new_df_dk['Subtitle'].replace({pd.NA: ''}, inplace=True)\n",
    "\n",
    "# Merge the values of 'title' and 'Subtitle' columns\n",
    "new_df_dk['title'] = new_df_dk['title'] + '. ' + new_df_dk['Subtitle']\n",
    "new_df_dk.drop(columns=['Subtitle'], inplace=True)\n",
    "\n",
    "\n",
    "new_df_dk.to_csv('bibliographic_data_DK.csv', index=False)\n",
    "new_df_dk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webscraping collections data and general bibliography\n",
    "\n",
    "\n",
    "# query on data.bnf - Klimt\n",
    "\n",
    "it's not possible to do a query directly using python, so this query:\n",
    "```PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX bnf-onto: <http://data.bnf.fr/ontology/bnf-onto/>\n",
    "SELECT * \n",
    "WHERE {\n",
    "  ?work dct:title ?title ;\n",
    "        dct:publisher ?publisher;\n",
    "        dct:date ?date;\n",
    "        rdfs:seeAlso ?uri ;\n",
    "        bnf-onto:isbn ?isbn\n",
    "  FILTER (bif:contains(?title, \"Klimt\"))}```\n",
    "\n",
    "has been done on the web endpoint and then the CSV was downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_k = pd.read_csv(\"databnf_KLI.csv\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "bnf_k.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in bnf_k.columns:\n",
    "    if column_name == \"isbn\":\n",
    "        for i, value in enumerate(bnf_k[column_name]):\n",
    "            if \"-\" in value:\n",
    "                # Replacing hyphens with empty string\n",
    "                bnf_k.at[i, column_name] = value.replace(\"-\", \"\")\n",
    "bnf_k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query on google books api - Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_books(query, max_results=40):\n",
    "    base_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "    start_index = 0\n",
    "    all_results = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"startIndex\": start_index,\n",
    "            \"maxResults\": max_results\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            items = data.get(\"items\", [])\n",
    "            if not items:\n",
    "                break\n",
    "            all_results.extend(items)\n",
    "            start_index += max_results\n",
    "        else:\n",
    "            print(\"Failed to retrieve data. Status code:\", response.status_code)\n",
    "            break\n",
    "\n",
    "    return all_results\n",
    "\n",
    "books_k = fetch_books(\"Klimt\")\n",
    "\n",
    "# Saving JSON data to a file\n",
    "with open(\"klimt_books.json\", \"w\") as json_file:\n",
    "    json.dump(books_k, json_file, indent=4)\n",
    "\n",
    "print(\"JSON data saved to klimt_books.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON data from file\n",
    "with open(\"klimt_books.json\", \"r\") as json_file:\n",
    "    books_data_k = json.load(json_file)\n",
    "\n",
    "# Extract relevant fields from each book item\n",
    "books_list_k = []\n",
    "for book in books_data_k:\n",
    "    book_info = {\n",
    "        \"Title\": book[\"volumeInfo\"].get(\"title\", \"N/A\"),\n",
    "        \"Subtitle\": book[\"volumeInfo\"].get(\"subtitle\", \"N/A\"),\n",
    "        \"Authors\": \", \".join(book[\"volumeInfo\"].get(\"authors\", [\"N/A\"])),\n",
    "        \"Publisher\": book[\"volumeInfo\"].get(\"publisher\", \"N/A\"),\n",
    "        \"PublishedDate\": book[\"volumeInfo\"].get(\"publishedDate\", \"N/A\"),\n",
    "        \"isbn\": book[\"volumeInfo\"].get(\"industryIdentifiers\", [{}])[0].get(\"identifier\", \"N/A\"),  # Retrieving ISBN\n",
    "    }\n",
    "    books_list_k.append(book_info)\n",
    "\n",
    "# Create DataFrame\n",
    "books_df_k = pd.DataFrame(books_list_k)\n",
    "books_df_k.replace('N/A', np.nan, inplace= True)\n",
    "\n",
    "# Display DataFrame\n",
    "books_df_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liss = []\n",
    "for column_name in books_df_k.columns:\n",
    "    if column_name == \"Title\":\n",
    "        for value in books_df_k[column_name]:\n",
    "            if \"Klimt\" in value or \"Klimt\" in value:\n",
    "                liss.append(value)\n",
    "print(len(liss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming books_df is your DataFrame\n",
    "# Assuming books_df is your DataFrame\n",
    "new_dataframe_k = books_df_k[books_df_k[\"Title\"].str.contains(\"Klimt\", case=False)]\n",
    "\n",
    "new_dataframe_k.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_dataframe_k.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'ISBN' column\n",
    "df_combined_k= pd.merge(bnf_k, new_dataframe_k, on='isbn', how='inner')\n",
    "\n",
    "# Display the new DataFrame with rows where ISBN is found in both DataFrames\n",
    "df_combined_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'Title' column in df2 to 'title'\n",
    "new_dataframe_k.rename(columns={'Title': 'title'}, inplace=True)\n",
    "new_dataframe_k.rename(columns={'PublishedDate': 'date'}, inplace=True)\n",
    "new_dataframe_k.rename(columns={'Publisher': 'publisher'}, inplace=True)\n",
    "# Concatenate the DataFrames vertically\n",
    "combined_df = pd.concat([bnf_k, new_dataframe_k], ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on 'isbn' column\n",
    "new_df_k = combined_df.drop_duplicates(subset='isbn')\n",
    "new_df_k = combined_df.drop_duplicates(subset=['title', 'publisher', 'date'], keep='first')\n",
    "# Reset index of the new DataFrame\n",
    "new_df_k.reset_index(drop=True, inplace=True)\n",
    "new_df_k.drop(columns=['work', 'uri'], inplace=True)\n",
    "index_column = new_df_k.columns.get_loc('Subtitle')\n",
    "\n",
    "# Move the column to position 2\n",
    "new_column_order = list(new_df_k.columns)\n",
    "new_column_order.insert(1, new_column_order.pop(index_column))\n",
    "new_df_k = new_df_k[new_column_order]\n",
    "\n",
    "for i, date_value in enumerate(new_df_k['date']):\n",
    "    # Convert integer to string before splitting\n",
    "    date_str = str(date_value)\n",
    "    # Split the date string by '-'\n",
    "    date_components = date_str.split('-')[0]\n",
    "    if '*' in date_components:\n",
    "        date_components = date_components.replace('*', '')  # Update here\n",
    "    # Update the 'date' column with the list of components\n",
    "    new_df_k.at[i, 'date'] = date_components\n",
    "    \n",
    "for i in new_df_k['Subtitle']:\n",
    "    if pd.isna(i):\n",
    "        new_df_k['Subtitle'].replace({pd.NA: ''}, inplace=True)\n",
    "\n",
    "# Merge the values of 'title' and 'Subtitle' columns\n",
    "new_df_k['title'] = new_df_k['title'] + '. ' + new_df_k['Subtitle']\n",
    "new_df_k.drop(columns=['Subtitle'], inplace=True)\n",
    "\n",
    "new_df_k.to_csv('bibliographic_data_KLI.csv', index=False)\n",
    "# Display the new DataFrame with unique rows based on ISBN and consistent column name 'title'\n",
    "new_df_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dk = new_df_dk.sort_values(by=\"date\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=new_df_dk, x=\"date\", color='#E97D01',  kde=True)\n",
    "plt.title(\"Distribution of Publication Years\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis tick labels by 45 degrees\n",
    "plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_k = new_df_k.sort_values(by=\"date\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=new_df_k, x=\"date\", color='#26408B',  kde=True)\n",
    "plt.title(\"Distribution of Publication Years\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis tick labels by 45 degrees\n",
    "plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Concatenate the dataframes and add a 'category' column to differentiate between them\n",
    "new_df_k['category'] = 'K'\n",
    "new_df_dk['category'] = 'DK'\n",
    "combined_df = pd.concat([new_df_k, new_df_dk])\n",
    "\n",
    "# Sort the combined dataframe by date\n",
    "combined_df = combined_df.sort_values(by=\"date\")\n",
    "\n",
    "# Plot the combined histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=combined_df, x=\"date\", hue=\"category\", palette={'K': '#26408B', 'DK': '#E97D01'})\n",
    "plt.title(\"Distribution of Publication Years\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis tick labels by 45 degrees\n",
    "plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "plt.legend(title='Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('../docs/data/comparison_publication_per_year.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count publishers - De Kooning\n",
    "\n",
    "\n",
    "# Assuming 'publisher' is the column name and new_df_k is your DataFrame\n",
    "publisher_counts_dk = new_df_dk['publisher'].replace('N/A', 'Unknown').value_counts()\n",
    "publisher_df_dk = pd.DataFrame({'publisher': publisher_counts_dk.index, 'count': publisher_counts_dk.values})\n",
    "publisher_df_dk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count authors - De Kooning\n",
    "\n",
    "\n",
    "# Assuming 'publisher' is the column name and new_df_k is your DataFrame\n",
    "authors_counts_dk = new_df_dk['Authors'].replace('N/A', 'Unknown').value_counts()\n",
    "authors_df_dk = pd.DataFrame({'authors': authors_counts_dk.index, 'count': authors_counts_dk.values})\n",
    "authors_df_dk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count publishers - Klimt\n",
    "\n",
    "\n",
    "# Assuming 'publisher' is the column name and new_df_k is your DataFrame\n",
    "publisher_counts_k = new_df_k['publisher'].replace('N/A', 'Unknown').value_counts()\n",
    "publisher_df_k = pd.DataFrame({'publisher': publisher_counts_k.index, 'count': publisher_counts_k.values})\n",
    "publisher_df_k.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count authors - Klimt\n",
    "\n",
    "\n",
    "# Assuming 'publisher' is the column name and new_df_k is your DataFrame\n",
    "authors_counts_k = new_df_k['Authors'].replace('N/A', 'Unknown').value_counts()\n",
    "authors_df_k = pd.DataFrame({'authors': authors_counts_k.index, 'count': authors_counts_k.values})\n",
    "authors_df_k.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot top 5 authors - De Kooning\n",
    "# # Assuming you have already created publisher_df DataFrame\n",
    "# top_authors_dk = authors_df_dk.head(5)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(top_authors_dk['authors'], top_authors_dk['count'], color='#26408B')\n",
    "# plt.xlabel('Publisher')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Top 5 Publishers')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot top 5 publishers- Klimt\n",
    "# # Assuming you have already created publisher_df DataFrame\n",
    "# top_publishers_k = publisher_df_kk.head(5)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(top_publishers['publisher'], top_publishers['count'], color='#3D60A7')\n",
    "# plt.xlabel('Publisher')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Top 5 Publishers')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot top 5 authors - Klimt\n",
    "# # Assuming you have already created publisher_df DataFrame\n",
    "# top_authors_k = authors_df_k.head(5)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(top_authors_k['authors'], top_authors_k['count'], color='#26408B')\n",
    "# plt.xlabel('Publisher')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Top 5 Publishers')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot top 5 publishers- Klimt\n",
    "# # Assuming you have already created publisher_df DataFrame\n",
    "# top_publishers_k = publisher_df_k.head(5)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(top_publishers['publisher'], top_publishers['count'], color='#3D60A7')\n",
    "# plt.xlabel('Publisher')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Top 5 Publishers')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 5 authors\n",
    "top_authors_dk = authors_df_dk.head(5)\n",
    "# Plot top 5 publishers\n",
    "top_publishers_dk = publisher_df_dk.head(5)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "\n",
    "# Plot top 5 authors\n",
    "axes[0].bar(top_authors_dk['authors'], top_authors_dk['count'], color='#B53302')\n",
    "axes[0].set_xlabel('Authors')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Top 5 Authors')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot top 5 publishers\n",
    "axes[1].bar(top_publishers_dk['publisher'], top_publishers_dk['count'], color='#E97D01')\n",
    "axes[1].set_xlabel('Publisher')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Top 5 Publishers')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot top 5 authors\n",
    "top_authors_k = authors_df_k.head(5)\n",
    "# Plot top 5 publishers\n",
    "top_publishers_k = publisher_df_k.head(5)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "\n",
    "# Plot top 5 authors\n",
    "axes[0].bar(top_authors_k['authors'], top_authors_k['count'], color='#26408B')\n",
    "axes[0].set_xlabel('Authors')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Top 5 Authors')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot top 5 publishers\n",
    "axes[1].bar(top_publishers_k['publisher'], top_publishers_k['count'], color='#3D60A7')\n",
    "axes[1].set_xlabel('Publisher')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Top 5 Publishers')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exhibitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhibition by Bibliography - De Kooning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many bibliographic records are actually exhibition catalogues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "total_rows = len(new_df_dk)\n",
    "\n",
    "# Count rows where 'title', 'subtitle', or 'description' contain specified keywords\n",
    "keyword_rows = new_df_dk[new_df_dk['title'].str.contains(r'exhibition|exhib\\.|mostra|catalogue|catalogo|exposition|retrospective|Ausstellung', case=False, na=False)]\n",
    "\n",
    "# Get the count of rows containing the specified keywords\n",
    "keyword_rows_count_dk = len(keyword_rows)\n",
    "\n",
    "print(\"Total rows in DataFrame:\", total_rows)\n",
    "print(\"Rows containing specified keywords:\", keyword_rows_count_dk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows containing specified keywords in 'title', 'subtitle', or 'description' columns\n",
    "mask = new_df_dk['title'].str.contains(r'exhibition|exhib\\.|mostra|catalogue |catalogo|exposition|retrospective|Ausstellung', case=False, na=False) \n",
    "\n",
    "# Create the exhibitions DataFrame containing rows where keywords are present\n",
    "exhibitions_dataframe_dk = new_df_dk[mask]\n",
    "\n",
    "# Remove the rows where keywords are present from the original DataFrame\n",
    "dfbooks_dk = new_df_dk[~mask]\n",
    "\n",
    "# Reset index of the original DataFrame\n",
    "dfbooks_dk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reset index of the exhibitions DataFrame\n",
    "exhibitions_dataframe_dk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"\\nExhibitions DataFrame:\")\n",
    "exhibitions_dataframe_dk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "# Process Text and Extract Location Names\n",
    "def extract_location(text):\n",
    "    doc = nlp(text)\n",
    "    locations = [entity.text for entity in doc.ents if entity.label_ == 'GPE']\n",
    "    return locations\n",
    "\n",
    "# Apply the extract_location function to the 'title' and 'Subtitle' columns and store the result in a new column 'locations'\n",
    "exhibitions_dataframe_dk['Exhibit locations'] = exhibitions_dataframe_dk.apply(lambda row: extract_location(row['title']), axis=1)\n",
    "\n",
    "# Convert the list of extracted locations into a comma-separated string\n",
    "exhibitions_dataframe_dk['Exhibit locations'] = exhibitions_dataframe_dk['Exhibit locations'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "exhibitions_dataframe_dk.to_csv('exhibitions_data_DK.csv', index=False)\n",
    "exhibitions_dataframe_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'date' is the column name and exhibitions_dataframe_k is your DataFrame\n",
    "date_counts_dk = exhibitions_dataframe_dk.groupby('date').size().reset_index(name='count')\n",
    "date_counts_dk = date_counts_dk.sort_values(by='date')\n",
    "\n",
    "# Display the DataFrame\n",
    "date_counts_dk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting with seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=date_counts_dk, x='date', y='count', color='#E97D01')\n",
    "plt.title('Exhibitions Count Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhibition by Bibliography - Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Count total rows of the DataFrame\n",
    "total_rows = len(new_df_k)\n",
    "\n",
    "# Count rows where 'title', 'subtitle', or 'description' contain specified keywords\n",
    "keyword_rows = new_df_k[new_df_k['title'].str.contains(r'exhibition|exhib\\.|mostra|catalogue|catalogo|exposition|retrospective|Ausstellung', case=False, na=False)  ]\n",
    "\n",
    "# Get the count of rows containing the specified keywords\n",
    "keyword_rows_count_k = len(keyword_rows)\n",
    "\n",
    "print(\"Total rows in DataFrame:\", total_rows)\n",
    "print(\"Rows containing specified keywords:\", keyword_rows_count_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your original DataFrame\n",
    "\n",
    "# Create a mask for rows containing specified keywords in 'title', 'subtitle', or 'description' columns\n",
    "mask = new_df_k['title'].str.contains(r'exhibition|exhib\\.|mostra|catalogue |catalogo|exposition|retrospective|Ausstellung', case=False, na=False) \n",
    "\n",
    "# Create the exhibitions DataFrame containing rows where keywords are present\n",
    "exhibitions_dataframe_k = new_df_k[mask]\n",
    "\n",
    "# Remove the rows where keywords are present from the original DataFrame\n",
    "dfbooks_k = new_df_k[~mask]\n",
    "\n",
    "# Reset index of the original DataFrame\n",
    "dfbooks_k.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reset index of the exhibitions DataFrame\n",
    "exhibitions_dataframe_k.reset_index(drop=True, inplace=True)\n",
    "exhibitions_dataframe_k.to_csv('exhibitions_data_KLI.csv', index=False)\n",
    "\n",
    "# Display the exhibitions DataFrame containing rows where keywords are present\n",
    "print(\"\\nExhibitions DataFrame:\")\n",
    "exhibitions_dataframe_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_location(text):\n",
    "    doc = nlp(text)\n",
    "    locations = [entity.text for entity in doc.ents if entity.label_ == 'GPE']\n",
    "    return locations\n",
    "\n",
    "\n",
    "# Apply the extract_location function to the 'title' and  columns and store the result in a new column 'locations'\n",
    "exhibitions_dataframe_k['Exhibit locations'] = exhibitions_dataframe_k.apply(lambda row: extract_location(row['title'] ), axis=1)\n",
    "\n",
    "# Convert the list of extracted locations into a comma-separated string\n",
    "exhibitions_dataframe_k['Exhibit locations'] = exhibitions_dataframe_k['Exhibit locations'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "exhibitions_dataframe_k.to_csv('exhibitions_data_KLI.csv', index=False)\n",
    "exhibitions_dataframe_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'date' is the column name and exhibitions_dataframe_k is your DataFrame\n",
    "date_counts_k = exhibitions_dataframe_k.groupby('date').size().reset_index(name='count')\n",
    "date_counts_k = date_counts_k.sort_values(by='date')\n",
    "\n",
    "# Display the DataFrame\n",
    "date_counts_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting with seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(data=date_counts_k, x='date', y='count', color='#26408B')\n",
    "# plt.title('Exhibitions Count Over Time')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting with seaborn\n",
    "sns.lineplot(data=date_counts_dk, x='date', y='count', color='#26408B', label='Exhibitions DK')\n",
    "sns.lineplot(data=date_counts_k, x='date', y='count', color='#FF5733', label='Exhibitions K')\n",
    "\n",
    "plt.title('Exhibitions Count Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Outer merge the DataFrames on the 'date' column\n",
    "merged_df = pd.merge(date_counts_dk, date_counts_k, on='date', how='outer')\n",
    "\n",
    "# Rename the count columns\n",
    "merged_df.rename(columns={'count_x': 'Exhibitions DK', 'count_y': 'Exhibitions K'}, inplace=True)\n",
    "\n",
    "# Sort by 'date'\n",
    "merged_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "# Plotting with seaborn\n",
    "sns.lineplot(data=merged_df, x='date', y='Exhibitions DK', color='#26408B', label='Exhibitions DK')\n",
    "sns.lineplot(data=merged_df, x='date', y='Exhibitions K', color='#FF5733', label='Exhibitions K')\n",
    "\n",
    "plt.title('Exhibitions Count Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../docs/data/comparison_exhibition_per_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De Kooning - a \"ground truth\" case\n",
    "\n",
    "### Complete list of De Kooning's one-man exibitions. \n",
    "In our research we considered also the number of exibitions and the venue of the exibitions as parameters in order to check whether the reputation of the artist has changed over the years. However, no complete dataset on artists' exhibitions was found. In order to get an idea on how many exibitions have been covered on catalogues, and, in particular, how many exhibitions are traced by bibliographic records on BnF and Gallica, we needed a \"ground truth\" to state if those sources of information could be somehow comprehensive. \n",
    "\n",
    "The case study is Willem de Kooning, since all data about exibitions are uploaded on the website of the Willem de Kooning Foundation. \n",
    "The result of the webscraping are shown here, with a total of 131 exhibitions, 81 possess a catalogue. \n",
    "\n",
    "In bibliography_DK.ipynb extraction from SPARQL endpoint of BnF and Google Books API has been done in order to get all bibliographic records on De Kooning - 31 of them are records on exhibitions. So 39% of exibitions with catalogue are present in that dataset, 23% of the total exhibitions are covered. There's also the need to say that the bibliographic records extracted do not concern only one-man shows, so they include further shows that are not present in the dataset reported here below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "URLs = [\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1940',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1950',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1960',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1970',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1980',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1990',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/2000',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/2010'\n",
    "] \n",
    "\n",
    "titles_list = []\n",
    "\n",
    "for url in URLs: \n",
    "    req = requests.get(url) \n",
    "    soup = bs(req.text, 'html.parser') \n",
    "    \n",
    "    titles = soup.find_all('p', class_=\"unit_title spacing_03\") \n",
    "    \n",
    "    for title in titles:\n",
    "        titles_list.append(title.text.strip().replace(\"\\xa0\\n\", \";\").replace(\"\\xa0\", \";\").replace('\\n',';'))\n",
    "\n",
    "\n",
    "titles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    \"Inc.\": \"Inc.\",\n",
    "    \"and\": \"and\",\n",
    "    \"Science\": \"Science\",\n",
    "    \"Ontario\": \"\",\n",
    "    \"The\": \"The\",\n",
    "    \"Palazzo\": \"Palazzo\",\n",
    "    \"Droll\": \"Droll\",\n",
    "    \"Fourcade\": \" Fourcade\",\n",
    "    \"University\": \"University\",\n",
    "    \"Ishibashi\": \"Ishibashi\",\n",
    "    \"Smithsonian\": \"Smithsonian\",\n",
    "    \"Millbrook\": \"Millbrook\",\n",
    "    \"Seattle\": \" Seattle\",\n",
    "    \"World\": \"World\",\n",
    "    \"Carnegie\": \"Carnegie\",\n",
    "    \"Akademie \": \"Akademie \",\n",
    "    \"Berkeley\": \"Berkeley\",\n",
    "    \"Wellesley\": \"Wellesley\",\n",
    "    \"Mitchell-Innes\": \"Mitchell-Innes\",\n",
    "    \"Art\": \"Art\",\n",
    "    \"Colorado\": \"Colorado\"\n",
    "}\n",
    "\n",
    "new_list = []\n",
    "\n",
    "# Iterate through each string in the original list\n",
    "for item in titles_list:\n",
    "    # Replace ';(' with ' ('\n",
    "    item = item.replace(';(', ' (')\n",
    "    \n",
    "    # Find the index of the first occurrence of \"catalogue.\" or \"brochure.\"\n",
    "    catalogue_index = item.find(\"catalogue.\")\n",
    "    brochure_index = item.find(\"brochure.\")\n",
    "    \n",
    "    # Determine the index of the first occurrence among \"catalogue.\" and \"brochure.\"\n",
    "    if catalogue_index != -1 and brochure_index != -1:\n",
    "        first_occurrence_index = min(catalogue_index, brochure_index)\n",
    "    elif catalogue_index != -1:\n",
    "        first_occurrence_index = catalogue_index\n",
    "    elif brochure_index != -1:\n",
    "        first_occurrence_index = brochure_index\n",
    "    else:\n",
    "        first_occurrence_index = len(item)\n",
    "    \n",
    "    # Slice the string up to the first occurrence\n",
    "    item = item[:first_occurrence_index + len(\"catalogue.\")]\n",
    "    \n",
    "    parts = item.split(';')\n",
    "\n",
    "    if len(parts) == 2:\n",
    "        second_part = parts[1]\n",
    "        # Iterate through each keyword in the replacements dictionary\n",
    "        for keyword, replacement in replacements.items():\n",
    "            if \", \" in second_part and keyword in second_part:\n",
    "                # Get the index of the keyword\n",
    "                keyword_index = second_part.index(keyword)\n",
    "                # Get the index of the last \", \" before the keyword\n",
    "                comma_index = second_part.rfind(\", \", 0, keyword_index)\n",
    "                # Replace \", \" with \" \" before the keyword\n",
    "                if comma_index != -1:  # Ensure \", \" was found before the keyword\n",
    "                    second_part = second_part[:comma_index] + \" \" + second_part[comma_index + 2:]\n",
    "                # Replace the keyword with the corresponding replacement\n",
    "                second_part = second_part.replace(keyword, replacement)\n",
    "        # Split the second part (after ';') by ','\n",
    "        second_parts = second_part.split(',')\n",
    "        # Remove the third element if the length is greater than 5\n",
    "        if len(second_parts) > 5:\n",
    "            del second_parts[1]\n",
    "        # Create a sublist with the first part and the second parts\n",
    "        sublist = [parts[0]] + second_parts\n",
    "        # Append the sublist to the new list\n",
    "        new_list.append(sublist)\n",
    "\n",
    "print(new_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Initialize empty lists for each column\n",
    "exhibition = []\n",
    "venue = []\n",
    "city = []\n",
    "state = []\n",
    "date = []\n",
    "catalogue = []\n",
    "\n",
    "# Populate the lists from the data in x\n",
    "for i in new_list:\n",
    "    if len(i) >= 6:\n",
    "        exhibition.append(i[0])\n",
    "        venue.append(i[1])\n",
    "        city.append(i[2])\n",
    "        state.append(i[3])\n",
    "        date.append(i[4])\n",
    "        catalogue.append(i[5])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Exhibition_name\", \"Venue\", \"City\", 'State', 'date', 'catalogue'])\n",
    "\n",
    "df['Exhibition_name'] = exhibition\n",
    "df['Venue'] = venue\n",
    "df['City'] = city\n",
    "df['State'] = state\n",
    "df['date'] = date\n",
    "df['catalogue'] = catalogue\n",
    "\n",
    "for i, item in enumerate(df['catalogue']): #modificato oggi\n",
    "    if \".\" in item:\n",
    "        x = item.split('.')\n",
    "        df.at[i, 'catalogue'] = x[0]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {}\n",
    "for element in df['catalogue']:\n",
    "    if element not in count_dict:\n",
    "        count_dict[element] = 1  \n",
    "    else:\n",
    "        count_dict[element] += 1  \n",
    "\n",
    "print(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i, item in enumerate(df['date']):\n",
    "\n",
    "    parts = item.strip('()').split(' to ')\n",
    "    modified_dates = []\n",
    "    for date_str in parts:\n",
    "        if \"??/??\" in date_str:\n",
    "            month_and_year = date_str.split('/')[-1]  # Extract month and year\n",
    "            modified_date = \"01/01/\" + month_and_year  # Replace day with \"01\"\n",
    "            modified_dates.append(modified_date)\n",
    "        elif '??' in date_str:\n",
    "            month_and_year = date_str.split('/')[0] + '/01/' + date_str.split('/')[-1]\n",
    "            modified_dates.append(month_and_year)\n",
    "        else:\n",
    "            modified_dates.append(date_str)\n",
    "    df.at[i, 'date'] = ' to '.join(modified_dates)\n",
    "    \n",
    "\n",
    "def extract_starting_range(date_str):\n",
    "    # Split the date range string by ' to ' or '-'\n",
    "    dates = date_str.strip('( )').split(' to ')\n",
    "    if len(dates) == 1:  # If ' to ' is not found, try splitting by '-'\n",
    "        dates = date_str.strip('( )').split('\\u2013')\n",
    "    if len(dates) < 2:\n",
    "        return None  \n",
    "    \n",
    "    starting_date = dates[0]\n",
    "    \n",
    "    # Convert the starting date to datetime format and extract the date part\n",
    "    return pd.to_datetime(starting_date, errors='coerce').date()\n",
    "\n",
    "\n",
    "def extract_ending_range(date_str):\n",
    "    dates = date_str.strip('( )').split(' to ')\n",
    "    if len(dates) == 1:  # If ' to ' is not found, try splitting by '-'\n",
    "        dates = date_str.strip('( )').split('\\u2013')\n",
    "    if len(dates) < 2:\n",
    "        return None  \n",
    "    ending_date = dates[1]\n",
    "    \n",
    "    # Convert the ending date to datetime format and extract the date part\n",
    "    return pd.to_datetime(ending_date, errors='coerce').date()\n",
    "\n",
    "\n",
    "# Apply the function to the 'date' column to create a new column with datetime objects\n",
    "df['startingdate'] = df['date'].apply(extract_starting_range)\n",
    "df['endingdate'] = df['date'].apply(extract_ending_range)\n",
    "\n",
    "\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webscraping monographs on de kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "URLs = [\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1950',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1960',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1970',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1980',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1990',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/2000',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/2010',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/2020'\n",
    "] \n",
    "\n",
    "titles_li = []\n",
    "\n",
    "for url in URLs: \n",
    "    req = requests.get(url) \n",
    "    soup = bs(req.text, 'html.parser') \n",
    "    \n",
    "    titles = soup.find_all('div', class_=\"unit_copy spacing_03\") \n",
    "    \n",
    "    for title in titles:\n",
    "        titles_li.append(title.text.strip().replace(\"\\xa0\\n\", \";\").replace(\"\\xa0\", \";\").replace('\\n',';').replace('\\t', '').replace(':;;', ': ').replace(\";;With\", \" With\")) \n",
    "\n",
    "titles_li\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "new_li = []\n",
    "\n",
    "# Iterate through each string in the original list\n",
    "for item in titles_li:\n",
    "\n",
    "# Split the string 'item' using either ';;' or ', 1' as the delimiter\n",
    "    parts = re.split(r';;|; ;', item)\n",
    "\n",
    "    new_li.append(parts)\n",
    "\n",
    "print(new_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Initialize empty lists for each column\n",
    "author = []\n",
    "title = []\n",
    "type = []\n",
    "publisher = []\n",
    "date = []\n",
    "\n",
    "# Populate the lists from the data in x\n",
    "for i in new_li:\n",
    "    if len(i) == 5:\n",
    "        author.append(i[0])\n",
    "        title.append(i[1])\n",
    "        if 'Exh.' in  i[2]  or 'PhD ' in i[2] or 'Series' in i[2]:\n",
    "            type.append(i[2])\n",
    "        else:\n",
    "            type.append('')\n",
    "        publisher.append(i[3])\n",
    "        date.append(i[4])\n",
    "    elif len(i) ==4:\n",
    "        if 'de Kooning' in i[1]:\n",
    "            author.append(i[0])\n",
    "            title.append(i[1])\n",
    "            type.append('')\n",
    "            publisher.append(i[2])\n",
    "            date.append(i[3])\n",
    "        elif 'de Kooning' in i[0] :\n",
    "            author.append('')\n",
    "            title.append(i[0])\n",
    "            type.append(i[1])\n",
    "            publisher.append(i[2])\n",
    "            date.append(i[3])\n",
    "        \n",
    "        \n",
    "\n",
    "# Create DataFrame\n",
    "dfs = pd.DataFrame({\"author\": author, \"title\": title, \"type\": type, 'publisher': publisher, 'date': date})\n",
    "dfs['publisher'] = dfs['publisher'].str.split(',').str[0]\n",
    "dfs['date'] = dfs['date'].str.extract(r'(\\d{4})')\n",
    "\n",
    "dfs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the real question\n",
    "## Is there any correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_dataframe_dk\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'soldtime' is the column name and final_auctions_dk is your DataFrame\n",
    "soldtime_counts = final_auctions_dk['soldtime'].value_counts().reset_index()\n",
    "soldtime_counts.columns = ['soldtime', 'count']\n",
    "\n",
    "# Sort the DataFrame based on 'soldtime'\n",
    "soldtime_counts_sorted = soldtime_counts.sort_values(by='soldtime')\n",
    "# Convert 'soldtime' values to type object\n",
    "soldtime_counts_sorted['soldtime'] = soldtime_counts_sorted['soldtime'].astype(str)\n",
    "\n",
    "# Output the DataFrame after conversion\n",
    "soldtime_counts_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df_dk = new_df_dk.sort_values(by=\"date\")\n",
    "# Assuming 'soldtime' is the column name and final_auctions_dk is your DataFrame\n",
    "publications_counts = new_df_dk['date'].value_counts().reset_index()\n",
    "publications_counts.columns = ['soldtime', 'count']\n",
    "\n",
    "# Sort the DataFrame based on 'soldtime'\n",
    "publications_counts = publications_counts.sort_values(by='soldtime')\n",
    "\n",
    "publications_counts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "publications_counts\n",
    "\n",
    "# Drop the last row\n",
    "publications_counts.drop(publications_counts.tail(1).index, inplace=True)\n",
    "\n",
    "\n",
    "publications_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on 'soldtime' from left and 'date' from right\n",
    "selling_publication_df = pd.merge(soldtime_counts_sorted, publications_counts, on='soldtime', how='inner',  suffixes=('-selling', '-publication'))\n",
    "\n",
    "# Output the merged DataFrame\n",
    "selling_publication_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "correlation_selling_publication = selling_publication_df['count-selling'].corr(selling_publication_df['count-publication'])\n",
    "\n",
    "# Display the correlation\n",
    "print(\"Correlation between count_selling and count_publication:\", correlation_selling_publication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=selling_publication_df, y='count-selling', x='count-publication')\n",
    "plt.title('Scatter Plot: Count Selling vs Count Publication')\n",
    "plt.xlabel('Count Selling')\n",
    "plt.ylabel('Count Publication')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_price_per_year_k\n",
    "\n",
    "# Assuming mean_price_per_year_k is your Series\n",
    "mean_price_per_year_k_df = mean_price_per_year_k.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "mean_price_per_year_k_df['soldtime'] = mean_price_per_year_k_df['soldtime'].astype(str)\n",
    "\n",
    "# Output the DataFrame\n",
    "mean_price_per_year_k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'soldtime' columns to string data type\n",
    "mean_price_per_year_k_df['soldtime'] = mean_price_per_year_dk_df['soldtime'].astype(str)\n",
    "publications_counts['soldtime'] = publications_counts['soldtime'].astype(str)\n",
    "\n",
    "# Merge the two DataFrames on 'soldtime' column\n",
    "mean_selling_publication_df = mean_price_per_year_k_df.merge( publications_counts, on='soldtime', how='inner')\n",
    "\n",
    "# Output the merged DataFrame\n",
    "mean_selling_publication_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "correlation_meanprice_publication = mean_selling_publication_df['price'].corr(mean_selling_publication_df['count'])\n",
    "\n",
    "# Display the correlation\n",
    "print(\"Correlation between count_selling and count_publication:\", correlation_meanprice_publication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=mean_selling_publication_df, y='price', x='count')\n",
    "plt.title('Scatter Plot: Count Selling vs Count Publication')\n",
    "plt.xlabel('Count Selling')\n",
    "plt.ylabel('Count Publication')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
